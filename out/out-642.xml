<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
<channel>
<title>Coding Horror</title>
<description>programming and human factors</description>
<link>https://blog.codinghorror.com/</link>
<pubDate>Sun, 19 Apr 2020 00:00:01 GMT</pubDate>
<!-- other elements omitted from this example -->
<item>
<title>Code Access Security and Bitfrost</title>
<link>https://blog.codinghorror.com/code-access-security-and-bitfrost/</link>
<content>
                <!--kg-card-begin: markdown--><p>
The <a href="http://www.laptop.org/">One Laptop Per Child</a> operating system features a new security model-- <a href="http://wiki.laptop.org/go/OLPC_Bitfrost">Bitfrost</a>. It's an interesting departure from the traditional UNIX and LINUX security model.
</p>
<p>
</p>
<blockquote>
The 1971 version of UNIX supported the following security permissions on user files:
<p>
</p>
<ul>
<li>non-owner can change file (write)
</li>
<li>non-owner can read file
</li>
<li>owner can change file (write)
</li>
<li>owner can read file
</li>
<li>file can be executed
</li>
<li>file is set-uid
</li>
</ul>
<p>
These permissions should look familiar, because they are very close to the same security permissions a user can set for her files today, in her operating system of choice. What's deeply troubling -- almost unbelievable -- about these permissions is that they've remained virtually the only real control mechanism that a user has over her personal documents today: a user can choose to protect her files from other people on the system, but has no control whatsoever over what her own programs are able to do with her files.
</p>
<p>
In 1971, this might have been acceptable: it was 20 years before the advent of the Web, and the threat model for most computer users was entirely different than the one that applies today. But how, then, is it a surprise that we can't stop viruses and malware now, when our defenses have remained largely unchanged from thirty-five years ago?
</p>
</blockquote>
<p>
BitFrost intends to address this problem by <b>adding a new level of permissions that applies to code</b>, not users: code access security.
</p>
<p>
</p>
<blockquote>
Consider the Solitaire game shipped with most versions of Microsoft Windows. This program needs:
<p>
</p>
<ul>
<li>no network access whatsoever
</li>
<li>no ability to read the user's documents
</li>
<li>no ability to utilize the built-in camera or microphone
</li>
<li>no ability to look at, or modify, other programs
</li>
</ul>
<p>
Yet if somehow compromised by an attacker, Solitaire is free to do whatever the attacker wishes, including:
</p>
<p>
</p>
<ul>
<li>read, corrupt or delete the user's documents, spreadsheets, music, photos and any other files
</li>
<li>eavesdrop on the user via the camera or microphone
</li>
<li>replace the user's wallpaper
</li>
<li>access the user's website passwords
</li>
<li>infect other programs on the hard drive with a virus
</li>
<li>download files to the user's machine
</li>
<li>receive or send e-mail on behalf of the user
</li>
<li>play loud or embarassing sounds on the speakers
</li>
</ul>
<p>
The critical observation here is not that Solitaire should never have the ability to do any of the above (which it clearly shouldn't), but that its creators know it should never do any of the above. If the system implemented a facility for Solitaire to indicate this at installation time, Solitaire could irreversibly shed various privileges the moment it's installed. This severely limits or destroys its usefulness to an attacker were it taken over.
</p>
</blockquote>
<p>
If I sound skeptical, that's because BitFrost sounds suspiciously similar to .NET framework code access security, as outlined in the <a href="http://msdn2.microsoft.com/en-us/library/system.security.permissions.aspx"><code>System.Security.Permissions</code></a> namespace. It's an enormous, complex list of explicit permissions you can grant or deny in your application's install manifest, exactly as described in the Solitaire example above. It sounds great in theory: establish a limited set of permissions your application needs up front, and let the .NET runtime worry about enforcing those permissions while your application is running.
</p>
<p>
But in practice, <a href="http://www.resolvecorp.com/blog/pierrenallet/PermaLink,guid,c4feb995-07bf-4087-a0cc-714d27505bc4.aspx">very few .NET developers make use of code access security</a>. It appears Microsoft noticed that, too:
</p>
<p>
</p>
<blockquote>
It seems Microsoft does not understand why nobody uses Code Access Security. In fact, Microsoft has <a href="http://blogs.msdn.com/brada/archive/2005/03/06/386172.aspx">a survey on the Internet</a>. You can go ahead and answer the survey but if you have followed this entry, you should know what I am getting at: <b>Code Access Security is too hard</b>. Don't get me wrong, I think Code Access Security is great. In particular, the stack walk mechanism is terrific. But the policy side is way too hard for most people.
</blockquote>
<p>
The CAS model was so profoundly unsuccessful in .NET 1.0 and 1.1 that <a href="http://www.leastprivilege.com/BewareBeAwareOfClickOnceDefaultSettings.aspx">ClickOnce in .NET 2.0 effectively does away with CAS</a>. You're now exactly one click away from running a full trust application that can do whatever it wants to on your machine, with no restrictions of any kind.
</p>
<p>
Perhaps the OLPC's BitFrost model will fare better than .NET Code Access Security did. But somehow I doubt it. <b>What good is a security model that's so cumbersome to use, nobody ever adopts it?</b>
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
            </content>
<pubDate>2007-03-20T13:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/code-access-security-and-bitfrost/</guid>
</item>
</channel>
</rss>
