<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
<channel>
<title>Coding Horror</title>
<description>programming and human factors</description>
<link>https://blog.codinghorror.com/</link>
<pubDate>Sun, 19 Apr 2020 00:00:01 GMT</pubDate>
<!-- other elements omitted from this example -->
<item>
<title>Three Monitors For Every User</title>
<link>https://blog.codinghorror.com/three-monitors-for-every-user/</link>
<content>
                <!--kg-card-begin: markdown--><p>
As far as I'm concerned, you can never be too rich, too thin, or have too much screen space. By "screen", I mean not just large monitors, but <i>multiple</i> large monitors. I've been evangelizing multiple monitors since the dark days of <a href="http://en.wikipedia.org/wiki/Windows_Me">Windows Millennium Edition</a>:
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.codinghorror.com/blog/archives/000012.html">Multiple Monitors and Productivity</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000217.html">Multiple LCDs</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000740.html">Joining the Prestigious Three Monitor Club</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000928.html">The Large Display Paradox</a>
</li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000959.html">LCD Monitor Arms</a>
</li>
</ul>
<p>
If you're a long time reader you're probably sick of hearing about this stuff by now, but something rather wonderful has happened since I last wrote about it:
</p>
<p>
</p>
<blockquote>
If you're only using one monitor, you are cheating yourself out of potential productivity. Two monitors is a no-brainer. It's so fundamental that I included it as a part of the <a href="http://www.codinghorror.com/blog/2006/08/the-programmers-bill-of-rights.html">Programmer's Bill of Rights</a>.
<p>
But you can do better.
</p>
<p>
<b>As good as two monitors is, three monitors is even better</b>. With three monitors, there's a "center" to focus on. And 50% more display area. While there's certainly a point of diminishing returns for additional monitors, I think three is the sweet spot. Even Edward Tufte, in the <a href="http://www.codinghorror.com/blog/archives/000739.html">class I recently attended</a>, explicitly mentioned multiple monitors. I don't care how large a single display can be; you can never have enough desktop space.
</p>
<p>
Normally, to achieve three monitors, you have to either:
</p>
<p>
</p>
<ol>
<li>Buy an exotic video card that has more than 2 monitor connections.
</li>
<li>Install a second video card.
</li>
</ol>
</blockquote>
<p>
Fortunately, that is no longer true. I was excited to learn that the latest ATI video cards have gone from two to three video outputs. Which means <b>you can now achieve triple monitors with a single video card upgrade!</b>  They call this <a href="http://sites.amd.com/us/underground/products/eyefinity/Pages/eyefinity.aspx">"eyefinity"</a>, but it's really just shorthand for "raising the standard from two display outputs to three".
</p>
<p>
But, there is a (small) catch. The PC ecosystem is in the middle of shifting display output standards. For evidence of this, you need look no further than the back panel of one of these newfangled triple display capable ATI video cards:
</p>
<p>
<img alt="Radeon-eyefinity-video-card-outputs" title="Radeon-eyefinity-video-card-outputs" src="https://blog.codinghorror.com/content/images/uploads/2010/04/6a0120a85dcdae970b01347fa6c999970c-800wi.jpg" border="0">
</p>
<p>
It contains:
</p>
<p>
</p>
<ul>
<li>two DVI outputs
</li>
<li>one HDMI output
</li>
<li>one <a href="http://en.wikipedia.org/wiki/DisplayPort">DisplayPort</a> output
</li>
</ul>
<p>
I suspect part of this odd connector layout is due to space restrictions (DVI is awfully chunky), but I've always understood DisplayPort to be the new, improved DVI connector for computer monitors, and HDMI to be the new, improved s-video/component connector for televisions. Of course these worlds are blurring, as <a href="http://www.codinghorror.com/blog/2006/12/will-your-next-computer-monitor-be-a-hdtv.html">modern high-definition TVs make surprisingly effective computer monitors</a>, too.
</p>
<p>
Anyway, since all my monitors have only DVI inputs, I wasn't sure what to do with the other output. So <a href="http://superuser.com/questions/118957/converting-displayport-and-or-hdmi-to-dvi-d">I asked on Super User</a>. The helpful answers led me to discover that, as I suspected, the third output has to be DisplayPort. So to connect my third monitor, I needed to <b>convert DisplayPort to DVI</b>, and there are two ways:
</p>
<p>
</p>
<ol>
<li>a <a href="http://www.amazon.com/dp/B0007MWE1Y/?tag=codihorr-20">passive, analog DisplayPort to DVI conversion cable</a> for ~$30 that supports up to 1920x1200
</li>
<li>an <a href="http://www.amazon.com/dp/B002ISVI3U/?tag=codihorr-20">active, digital DisplayPort to DVI converter</a> for $110 that supports all resolutions
</li>
</ol>
<p>
I ended up going with the active converter, which has mixed reviews, but it's worked well for me over the last few weeks.
</p>
<p>
<a href="http://www.amazon.com/dp/B002ISVI3U/?tag=codihorr-20"><img class="asset  asset-image at-xid-6a0120a85dcdae970b01347fa6eaab970c" alt="Accell-ultraav-displayport-to-dvi-adapter" title="Accell-ultraav-displayport-to-dvi-adapter" src="https://blog.codinghorror.com/content/images/uploads/2010/04/6a0120a85dcdae970b01347fa6eaab970c-800wi.jpg" border="0"></a>
</p>
<p>
Note that this adapter requires USB power, and given the spotty results others have had with it, some theorize that it needs quite a bit of juice to work reliably. I plugged it into my system's nearby rear USB ports which do tend to deliver more power (they're closer to the power supply, and have short cable paths). Now, I <i>have</i> gotten the occasional very momentary black screen with it, but nothing severe enough to be a problem or frequent enough to become a pattern. If you have DisplayPort compatible monitors, of course, this whole conversion conundrum is a complete non-issue. But DisplayPort is fairly new, and even my new-ish LCD monitors don't support it yet.
</p>
<p>
The cool thing about this upgrade, besides <a href="http://www.codinghorror.com/blog/2008/11/feeding-my-graphics-card-addiction.html">feeding my video card addiction</a>, is that <b>I was able to simplify my hardware configuration</b>. That's always good. I went from two video cards to one, which means less power consumption, simpler system configuration, and fewer overall driver oddities. Basically, it makes triple monitors -- dare I say it -- almost a <i>mainstream</i> desktop configuration. How could I not be excited about that?
</p>
<p>
I was also hoping that Nvidia would follow ATI's lead here and <b>make three display outputs the standard for all their new video cards</b>, too, but sadly that's not the case. It turns out their new GTX 480 fails in other ways, in that <a href="http://www.maximumpc.com/article/features/nvidias_hot_rod_gtx_480_powerful_and_power_hungry?page=0,1">it's basically the Pentium 4 of video cards</a> -- generating ridiculous amounts of heat for very little performance gain. Based on those two facts, I am comfortable endorsing ATI wholeheartedly at this point. But, do be careful, because not all ATI cards support triple display outputs (aka "eyefinity"). These are the ones that I know do:
</p>
<p>
</p>
<p>
</p>
<ul>
<li>
<a href="http://www.amazon.com/dp/B0033WSDO2/?tag=codihorr-20">Radeon HD 5670</a> (~$100)
</li>
<li>
<a href="http://www.amazon.com/dp/B002SP113K/?tag=codihorr-20">Radeon HD 5770</a> (~$150)
</li>
<li>
<a href="http://www.amazon.com/dp/B0039YOMZI/?tag=codihorr-20">Radeon HD 5830</a> (~$250)
</li>
<li>
<a href="http://www.amazon.com/dp/B002QEBGGA/?tag=codihorr-20">Radeon HD 5850</a> (~$320)
</li>
<li>
<a href="http://www.amazon.com/dp/B003D0QQJS/?tag=codihorr-20">Radeon HD 5870</a> (~$450)
</li>
</ul>
<p>
Unless you're a gamer, there's no reason to care about anything other than the least expensive model here, which will handily <i>crush</i> any 2D or 3D desktop GUI acceleration needs you might have. As an addict, of course I bought the high end model and it absolutely did not disappoint -- more than doubling my framerates in the excellent game <a href="http://www.amazon.com/dp/B002NIP2SM/?tag=codihorr-20">Battlefield: Bad Company 2</a> over the GTX 280 I had <a href="http://www.codinghorror.com/blog/2008/11/feeding-my-graphics-card-addiction.html">before</a>.
</p>
<p>
I'm excited that a triple monitor setup is now, thanks to ATI, so easily attainable for desktop users -- as long as you're aware of the DisplayPort caveat I discussed above. I'd encourage anyone who is even <i>remotely</i> interested in the (many) productivity benefits of a triple monitor setup to seriously consider an ATI video card upgrade.
</p>
<p>
</p>
<p>
<!--kg-card-end: markdown-->
            </p></content>
<pubDate>2010-04-04T22:10:08.000Z</pubDate>
<guid>https://blog.codinghorror.com/three-monitors-for-every-user/</guid>
</item>
</channel>
</rss>
