<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
<channel>
<title>Coding Horror</title>
<description>programming and human factors</description>
<link>https://blog.codinghorror.com/</link>
<pubDate>Sun, 19 Apr 2020 00:00:01 GMT</pubDate>
<!-- other elements omitted from this example -->
<item>
<title>Some Plan(s) for Spam</title>
<link>https://blog.codinghorror.com/some-plans-for-spam/</link>
<content>
                <!--kg-card-begin: markdown--><p>
After struggling with spam e-mail for years the old fashioned way-- highlight, DEL-- I finally succumbed and installed <a href="http://popfile.sourceforge.net/">POPFile</a> on my server. POPFile uses a <a href="http://www.process.com/precisemail/bayesian_filtering.htm">Bayesian Filter</a> technique and it is amazingly effective. Within a day I had 95% accuracy; within a week I had 97% accuracy. Two months later, I'm up to nearly 99% accuracy:
</p>
<p>
<img alt="98.6 percent accuracy" height="72" src="http://www.codinghorror.com/blog/images/screenshot_popfile_accuracy.gif" width="319">
</p>
<p>
It's interesting that bayesian filtering is so effective, yet <b>most people never heard of it until mid 2002.</b> Spam has been around seemingly forever; why wasn't this technique adopted sooner? I did some digging and came up with Paul Graham's <a href="http://www.paulgraham.com/spam.html">A Plan For Spam</a>. Paul is an interesting guy with a LISP background, and although he probably wasn't the first person to think of using Bayesian techniques to fight spam, he was definitely the first person to stump for <a href="http://www.paulgraham.com/better.html">a workable algorithm</a>:
</p>
<blockquote>
I don't know why I avoided trying the statistical approach for so long. I think it was because I got addicted to trying to identify spam features myself, as if I were playing some kind of competitive game with the spammers. (Nonhackers don't often realize this, but most hackers are very competitive.) When I did try statistical analysis, I found immediately that it was much cleverer than I had been. It discovered, of course, that terms like "virtumundo" and "teens" were good indicators of spam. But it also discovered that "per" and "FL" and "ff0000" are good indicators of spam. In fact, "ff0000" (html for bright red) turns out to be as good an indicator of spam as any pornographic term.
<p>
But the real advantage of the Bayesian approach, of course, is that you know what you're measuring. Feature-recognizing filters like SpamAssassin assign a spam "score" to email. The Bayesian approach assigns an actual probability. The problem with a "score" is that no one knows what it means. The user doesn't know what it means, but worse still, neither does the developer of the filter. How many points should an email get for having the word "sex" in it? A probability can of course be mistaken, but there is little ambiguity about what it means, or how evidence should be combined to calculate it. Based on my corpus, "sex" indicates a .97 probability of the containing email being a spam, whereas "sexy" indicates .99 probability. And Bayes' Rule, equally unambiguous, says that an email containing both words would, in the (unlikely) absence of any other evidence, have a 99.97% chance of being a spam.
</p>
<p>
Because it is measuring probabilities, the Bayesian approach considers all the evidence in the email, both good and bad. Words that occur disproportionately rarely in spam (like "though" or "tonight" or "apparently") contribute as much to decreasing the probability as bad words like "unsubscribe" and "opt-in" do to increasing it. So an otherwise innocent email that happens to include the word "sex" is not going to get tagged as spam.
</p>
</blockquote>
I know what you're thinking now: say I'm a spammer. <b>How would I beat a Bayesian Filter?</b> Well, it's possible, but it's hard:
<blockquote>
Assuming they could solve the problem of the headers, the spam of the future will probably look something like this:
<p>
</p>
<blockquote>
Hey there.  Thought you should check out the following:<br>
<a href="http://www.27meg.com/foo">http://www.27meg.com/foo</a>
</blockquote>
<p>
because that is about as much sales pitch as content-based filtering will leave the spammer room to make. (Indeed, it will be hard even to get this past filters, because if everything else in the email is neutral, the spam probability will hinge on the url, and it will take some effort to make that look neutral.)
</p>
<p>
Spammers range from businesses running so-called opt-in lists who don't even try to conceal their identities, to guys who hijack mail servers to send out spams promoting porn sites. If we use filtering to whittle their options down to mails like the one above, that should pretty much put the spammers on the "legitimate" end of the spectrum out of business; they feel obliged by various state laws to include boilerplate about why their spam is not spam, and how to cancel your "subscription," and that kind of text is easy to recognize.
</p>
</blockquote>
Digging through today's email for examples-- what about <b>messages with no text, only HTML images</b>?
<p>
</p>
<pre>
Received: from host-122-195.firstpointsecure.com ([69.42.122.195]) by server.mydomain.com with Microsoft SMTPSVC(6.0.3790.0);
Sun, 19 Sep 2004 14:32:43 -0400
From: "Good News" &lt;rodfournier@moquije.remarkablenews.com&gt;
To: me &lt;me@mydomain.com&gt;
Subject: Single?
Date: Sun, 19 Sep 2004 11:32:56 -0800
MIME-Version: 1.0
Content-type: text/html; charset="ISO-8859-1"
Content-transfer-encoding: 7bit
Message-Id: &lt;0771687B7E76766B477E707A6C346C697C7A70756C7A7A356A7674$4df803ge2@moquije.remarkablenews.com&gt;
Return-Path: rodfournier@moquije.remarkablenews.com
&lt;html&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;p align="center"&gt;&lt;a href="http://quugot.deliveredsavings.com/date3/?i=iog0771687b7e76766b4v&amp;vj=jzv77e707a6c346c697c7ig&amp;n=ksia70756c7a7a356a7674k&amp;pq=vtyk&amp;winner&amp;_m01"&gt;
&lt;img border="0" src="http://quugot.deliveredsavings.com/date3/at.gif" width="383" height="210"&gt;&lt;/a&gt;&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
&lt;/p&gt;
&lt;p align="center"&gt;
&lt;a href="http://quugot.deliveredsavings.com/date3/rd.cgi?i=iog0771687b7e76766b4v&amp;vj=jzv77e707a6c346c697c7ig&amp;n=ksia70756c7a7a356a7674k&amp;pq=vtyk&amp;winner&amp;_m01"&gt;
&lt;img border="0" src="http://quugot.deliveredsavings.com/date3/5.gif" width="502" height="59"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align="center"&gt;&lt;/p&gt;
&lt;img src="http://quugot.deliveredsavings.com/date3/logogen.img?i=iog0771687b7e76766b4v&amp;vj=jzv77e707a6c346c697c7ig&amp;n=ksia70756c7a7a356a7674k&amp;pq=vtyk" border=0&gt;
&lt;/body&gt;
&lt;/html&gt;
</pre>
<p>
Or <b>messages with non-spam spoof text</b>?
</p>
<p>
</p>
<pre>
&lt;font size="2" face="Verdana"&gt;Stop this &lt;a href="http://www.muss4267pinn.com/a.ddd"&gt;please&lt;/a&gt;!&lt;/font&gt;&lt;br&gt;
&lt;br&gt;
christy passport nocturnal director cargoes corrigendum sicklewort doria polaroid &lt;br&gt;
&lt;br&gt;
</pre>
<p>
Interestingly, <a href="http://popfile.sourceforge.net/">POPFile</a> has no problem at all correctly categorizing these messages as spam. That's the value of parsing the headers and the HTML, something early researchers failed to do. Graham <a href="http://www.paulgraham.com/better.html">cites this as the primary reason why Bayesian filtering</a> wasn't used prior to 2002. They didn't think it was effective enough!
</p>
<p>
98.6 percent accuracy is good, one of the best available, but it's not 100 percent. Can we do better with other spam fighting techniques? I agree with Graham's position that <a href="http://www.paulgraham.com/falsepositives.html">blacklists are both a bad idea and a losing battle</a>, so I won't even go there. Whitelists, on the other hand, are more interesting. Take a service like <a href="http://spamarrest.com/">SpamArrest</a>, for example. This works like so:
</p>
<ol>
<li>Joe sends you an email.
</li>
<li>An auto-generated response is sent to Joe, explaining that you are fighting spam, and that his email won't be delivered until he visits the provided URL.
</li>
<li>Joe clicks the URL, enters the <a href="http://www.captcha.net/">CAPTCHA</a> value, and clicks OK.
</li>
<li>Joe's email address is now verified human, and his email is delivered to you.
</li>
<li>All further emails from Joe will arrive without this additional step.
</li>
</ol>
This type of whitelist delivers damn near 100% effective spam blocking, with no training period required. There's simply no way a machine can pass this test. <b>This works great if you commit to only accepting email from human beings.</b> The downside is, you still have to go through your spam folder to manually authorize any automated emails: newsletters, order confirmations, and so forth. Even though you've gone from 2% spam to 0% spam, you probably want to check your rejected email folder periodically.
<p>
Some people <a href="http://weblogs.asp.net/jkey/archive/2004/08/14/214608.aspx">love whitelists</a>. I'm not a fan. Putting the burden of verification on the sender seems kind of onerous to me. Even though it's a one time thing, it is an additional hurdle for every person that wants to communicate with me. On the other hand, this type of anti-machine whitelist is a reasonable approach to an intractable problem. Bayes will always let <i>some</i> spam slip through, so it is arguably the only way to get an ironclad "100 percent" effective spam blocking.
</p>
<p>
</p>
<p></p>
<!--kg-card-end: markdown-->
            </content>
<pubDate>2004-09-19T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/some-plans-for-spam/</guid>
</item>
</channel>
</rss>
