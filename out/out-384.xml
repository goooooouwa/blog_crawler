<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
<channel>
<title>Coding Horror</title>
<description>programming and human factors</description>
<link>https://blog.codinghorror.com/</link>
<pubDate>Sun, 19 Apr 2020 00:00:01 GMT</pubDate>
<!-- other elements omitted from this example -->
<item>
<title>Building a PC, Part V: Upgrading</title>
<link>https://blog.codinghorror.com/building-a-pc-part-v-upgrading/</link>
<content>
                <!--kg-card-begin: markdown--><p>Last summer I posted a four part series on building your own PC:</p>
<p> </p>
<ul>
<li>
<a href="http://www.codinghorror.com/blog/archives/000905.html">Building a PC, Part I: Minimal boot</a> </li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000907.html">Building a PC, Part II: Burn in</a> </li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000908.html">Building a PC, Part III: Overclocking</a> </li>
<li>
<a href="http://www.codinghorror.com/blog/archives/000918.html">Building a PC, Part IV: Now It's Your Turn</a> </li>
</ul>
<p>My personal system is basically identical to that build, though it predates it by <a href="http://www.codinghorror.com/blog/archives/000707.html">about six months</a>. The only significant difference is the substitution of the Core 2 Duo E6600 CPU.</p>
<p>In my opinion, quad-core CPUs are still a <a href="http://www.codinghorror.com/blog/archives/000942.html">waste of electricity</a> unless you're putting them in a server. Four cores on the desktop is great for bragging rights and mathematical superiority (yep, 4 &gt; 2), but those four cores <a href="http://www.codinghorror.com/blog/archives/000655.html">provide almost no benchmarkable improvement</a> in the type of applications most people use. Including software development tools. (<span style="color: red;">Update:</span> This paragraph was more controversial than intended. See <a href="http://www.codinghorror.com/blog/archives/001103.html">Should All Developers Have Manycore CPUs?</a> for a clarification.)</p>
<p><img class="at-xid-6a0120a85dcdae970b0120a86ddbce970b" src="https://blog.codinghorror.com/content/images/uploads/2008/04/6a0120a85dcdae970b0120a86ddbce970b-pi.jpg" border="0" alt="e6600-cpu-pic.jpg" width="689" height="568"></p>
<p>My original advice stands: for the vast majority of users, the fastest possible dual-core CPU remains the best choice. I overclocked my E6600 CPU <strong>from 2.4 Ghz to 3.2 Ghz</strong>, instantly increasing the value of the processor by about 800 bucks.</p>
<p>Beyond overclocking, <strong>the economy of building your own PC also lies in upgrading it in pieces and parts to keep it up to date</strong>. Once you've taught yourself to build a PC, swapping parts out is easy. That's an option you almost never have on laptops, and rarely on commercial desktops.</p>
<p>It's been almost a year and a half since I made any significant change to my PC build. That's an eternity in computer dog years. I was developing a serious itch to upgrade something -- <em>anything</em> -- on my PC. I did a bit of research, and I was surprised to find that the P965 chipset on my Asus P5B Deluxe motherboard supports the latest and greatest Intel CPUs. This is a pleasant surprise indeed; Intel and AMD change the pinouts and sockets of their CPUs quite regularly. A simple CPU upgrade, more often than not, forces a complete motherboard and memory upgrade. But not in this case!</p>
<p>So here's what I did:</p>
<ol>
<li>flash the BIOS* on my motherboard to the latest version, which supports the newest CPUs </li>
<li>remove the old and busted CPU (Core 2 Duo E6600, 2.4 GHz, 4 MB L2) </li>
<li>drop in the new hotness CPU (Core 2 Duo E8500, 3.16 GHz, 6 MB L2) </li>
<li>Manually <a href="http://www.codinghorror.com/blog/archives/000697.html">adjust FSB speed, memory voltage and CPU voltage</a> </li>
</ol>
<p>This chip is an <em>outstanding</em> overclocker. It's almost a no-brainer. The tubes are <a href="http://www.google.com/search?q=e8500+overclocking">full of documented cases</a> of this chip reaching 4.5 GHz and sometimes higher. I was fairly content with <strong>my effortless 4 GHz overclock</strong>:</p>
<p><img class="at-xid-6a0120a85dcdae970b0120a86ddbeb970b" src="https://blog.codinghorror.com/content/images/uploads/2008/04/6a0120a85dcdae970b0120a86ddbeb970b-pi.png" border="0" alt="cpu-z E8500 @ 4 GHz" width="384" height="408"></p>
<p>If you're wondering why <a href="http://www.cpuid.com/cpuz.php">CPU-Z</a> says this is a 2520 MHz CPU instead of the 4000 MHz you'd expect, that's because the CPU is idle. All modern CPUs <a href="http://en.wikipedia.org/wiki/SpeedStep">clock down at idle</a> to reduce power draw. If you run something CPU intensive, you'll see the CPU speed dynamically change in CPU-Z, as illustrated by this animated GIF:</p>
<p><img class="at-xid-6a0120a85dcdae970b0120a86ddc03970b" src="https://blog.codinghorror.com/content/images/uploads/2008/04/6a0120a85dcdae970b0120a86ddc03970b-pi.gif" border="0" alt="CPU-Z SpeedStep animation" width="188" height="100"></p>
<p>This power savings is achieved by dropping the CPU multiplier from its default of 9.5 down to 6.0. If we do a little math, it's easy to infer the relationship between FSB (front side bus), CPU multiplier, and actual CPU speed:</p>
<p> </p>
<table cellspacing="4" cellpadding="4" width="400">
<tbody>
<tr>
<td>315 MHz</td>
<td>6.0x</td>
<td>1890 MHz</td>
</tr>
<tr>
<td>333 MHz</td>
<td>9.5x</td>
<td>3163 MHz</td>
</tr>
<tr>
<td>420 MHz</td>
<td>6.0x</td>
<td>2520 MHz</td>
</tr>
<tr>
<td><span style="color: red;">420 MHz</span></td>
<td><span style="color: red;">9.5x</span></td>
<td><span style="color: red;">3990 MHz</span></td>
</tr>
</tbody>
</table>
<p> </p>
<p>Overclocking the CPU is simple if you can stumble your way through a few basic BIOS screens. The default voltage on this E8500 is 1.128 volts. By juicing the CPU voltage up to 1.36 volts, and setting the front side bus (FSB) to 420 MHz, we can hit the magical 4 GHz number. All we need to do is a little unit testing<a href="http://www.codinghorror.com/blog/archives/000907.html">burn-in torture testing</a>, and we can confirm that it's stable.</p>
<p>But you might wonder -- does this overclocking stuff really justify the hassle? Is <strong>going from 3.0 GHz to 4.0 GHz really <em>worth</em> it in terms of actual performance and not just bragging rights?</strong></p>
<p>I'm glad you asked!</p>
<p>I clocked my E8500 to 3.0 GHz / 315 FSB and 4.0 GHz / 420 FSB and ran a few quick <a href="http://webkit.org/perf/sunspider-0.9/sunspider.html">SunSpider JavaScript benchmarks</a>. You may remember this great little benchmark from <a href="http://www.codinghorror.com/blog/archives/001023.html">The Great Browser JavaScript Showdown</a>.  Here's what I found:</p>
<p><img class="at-xid-6a0120a85dcdae970b0120a86ddc19970b" src="https://blog.codinghorror.com/content/images/uploads/2008/04/6a0120a85dcdae970b0120a86ddc19970b-pi.png" border="0" alt="JavaScript Sunspider CPU Performance from 3 GHz to 4 GHz" width="699" height="598"></p>
<p>And the overall benchmark result in table form:</p>
<p> </p>
<table cellspacing="4" cellpadding="4" width="500">
<tbody>
<tr>
<td> </td>
<td align="right">3 GHz</td>
<td align="right">4 GHz</td>
<td> </td>
</tr>
<tr>
<td>Internet Explorer 7 SP1</td>
<td align="right">15,824 ms</td>
<td align="right">12,748 ms</td>
<td>19% faster</td>
</tr>
<tr>
<td>Firefox 3.0 Beta 5</td>
<td align="right">3,018 ms</td>
<td align="right">2,450 ms</td>
<td>19% faster</td>
</tr>
</tbody>
</table>
<p> </p>
<p>That's <strong>a consistent 19% performance improvement in an interpreted browser language for a 33% increase in raw CPU clock speed</strong>. Not too shabby. It's actually more than I expected. The real speed difference between an E6600 and E8500 would be (slightly) greater than the pure clock speed indicates, due to the architectural improvements and larger L2 cache in the E8500. There also might be other languages and apps that scale more linearly with that 33% CPU clock speed increase.</p>
<p><strong>Compare the result of going from 3 GHz to 4 GHz with adding another two cores</strong>, which would produce exactly <em>zero</em> improvement in your JavaScript benchmarks. Most apps are barely multithreaded, much less capable of taking advantage of all four cores. Having four CPU cores won't help you much when they're all poking along at a leisurely 2 GHz.</p>
<p>So if you followed our original PC build plan, or if you're planning to build your own PC -- <strong>don't forget to factor upgrading into your system's lifespan!</strong> These builds are eminently upgradeable. Sometimes you'll get lucky and have <em>knockout</em> upgrade options like the E8500: a 4 GHz (almost) guaranteed drop-in CPU replacement for under 300 bucks.</p>
<p><span>* I am simplifying a little because I don't want to scare anyone. In the interests of full disclosure, here's the story. The ASUS Windows x64 BIOS flash program crashed while updating the motherboard BIOS. I can't quite describe the chill that went down my spine as I watched this happen. Any failure during a BIOS flash is irrevocable and permanent, the very definition of "bricking". To be fair, this is literally the first time I've ever bricked <em>anything</em> in at least 10 years of regular yearly BIOS flashing. I had to buy another motherboard and initiate a RMA on my original, newly BIOS-free motherboard. Let this be a lesson to you, kids: don't trust Windows software developers! Always update the BIOS from a boot CD or from within the BIOS itself using a USB key!</span></p>
<!--kg-card-end: markdown-->
            </content>
<pubDate>2008-04-17T12:00:00.000Z</pubDate>
<guid>https://blog.codinghorror.com/building-a-pc-part-v-upgrading/</guid>
</item>
</channel>
</rss>
